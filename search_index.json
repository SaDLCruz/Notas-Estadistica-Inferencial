[["conceptos-iniciales.html", "Pruebas de hipótesis de una muestra 1 Conceptos iniciales 1.1 ¿Qué es una hipótesis estadística? 1.2 Errores de inferencia 1.3 Región crítica y reglas de decisión", " Pruebas de hipótesis de una muestra Sadan De la Cruz Almanza (Departamento de Economía - Universidad de Pamplona) 1 Conceptos iniciales 1.1 ¿Qué es una hipótesis estadística? La palabra hipótesis puede ser utilizada en diferentes contextos. En general, se puede definir como “un enunciado no verificado, que se intenta confirmar o refutar” (wiki). Desde una perspectiva estadística, la hipotesis tiene una fuerte relación con el concepto de estimación. Una hipótesis estadística “es una afirmación con respecto a alguna característica desconocida deuna población de interés” (Canavos, 1988). En esencia al probar una hipótesis estadística, buscamos decidir si la afirmación propuesta se encuentra se encuentra apoyadq por la evidencia experimental que se obtiene a través de una muestra aleatoria. Dicha decisión se fundamenta con base en probabilidades, en otras palabras si contamos con “suficiente evidencia estadística” aceptaremos o rechazaremos la hipótesis. En terminos generales, vamos a identificar la hipótesis nula (\\(H_0\\)) y la hipótesis alternativa (\\(H_1\\)). El primer caso se relaciona con la definición inicial, y en el segundo, refleja “el valor posible o intervalo de valores del parámetro de interés si la hipótesis nula es falsa” (Canavos, 1988, p. 308). Por otro lado, prueba estadística respecto a “una característica desconocida de la población de interés es cualquier regla para decidir si se rechaza la hipótesis nula con base en una muestra aleatoria de la población” (Canavos, 1988, p. 306). # paquetes library(ggplot2) library(haven) library(dplyr) # Remesas, Colombia (2014 - 2023) # Cargar base de datos en un formato .dta bd &lt;- read_dta(&quot;/Users/macbookait/Documents/Investigación/Investigación/Remesas/datos/bd_remesas.dta&quot;) # DIAGRAMA DE CAJA Y BIGOTES #El diagrama muestra la distribución, la mediana y la variabilidad de los datos. bd$country &lt;- factor(bd$country) bd$dpto &lt;- factor(bd$dpto) # Departamentos ggplot(bd, aes(x = dpto, y = consignment)) + geom_boxplot() + theme_classic() # Países ggplot(bd, aes(x = country, y = consignment, fill=country)) + geom_boxplot() + theme_classic() # SERIE DE TIEMPO bd &lt;- bd %&gt;% mutate(date = paste(year, &quot;Q&quot;, quarter, sep = &quot;&quot;)) bd1 &lt;- bd %&gt;% group_by(country, date) %&gt;% summarize(consignment_mean = mean(consignment), .groups = &#39;drop&#39;) bd1 &lt;- bd1 %&gt;% mutate(date = factor(date, levels = unique(date))) ggplot(bd1, aes(x = date, y = consignment_mean, color = country, group = country)) + geom_line() + geom_point() + theme_classic() # GRÁFICA DE DENSIDAD POR GRUPOS means_by_country &lt;- bd1 %&gt;% group_by(country) %&gt;% summarize(mean_consignment = mean(consignment_mean)) ggplot(bd1, aes(x = consignment_mean)) + geom_density() + geom_vline(data = means_by_country, aes(xintercept = mean_consignment), color=&quot;blue&quot;, linetype=&quot;dashed&quot;, size = 1) + facet_wrap(~ country, scales = &quot;free&quot;) 1.2 Errores de inferencia En estadística inferencial saber “aceptar” o “rechazar” la hipótesis propuesta es importante respecto al “que decir” de los datos. Error tipo I: El rechazo de \\(H_0\\) cuando en realidad \\(H_0\\) es cierto. Esto es posible cuando la decisión es rechazar la hipótesis nula. Error tipo II: Equivocarse al rechazar \\(H_0\\) cuando en realidad \\(H_0\\) es falsa. Esto es posible cuando la decisión es no rechazar la hipótesis nula. Como se menciono en clases anteriores, la idea de la estadística es encontrar el estado “natural” de nuestros fenomenos económicos (población) a partir de una muestra. En este caso, la siguiente tabla proporciona un resumen respecto a la decisión tomada: Población (“Verdad”) Muestra \\(H_0\\) es verdadero \\(H_0\\) es falsa No rechazar\\(H_0\\) Decisión correcta (Pr = 1 - \\(\\alpha\\) ) Error tipo II (Pr = \\(\\beta\\)) Rechazar \\(H_0\\) Error tipo I (Pr = \\(\\alpha\\)) Decisión correcta (Pr = 1 - \\(\\beta\\)) En todo caso, \\(0 \\leq \\alpha \\leq 1\\) y \\(0 \\leq \\beta \\leq 1\\). \\(\\alpha\\), \\(\\beta\\) permiten medir la posibilidad de cometer alguno de estos errores. Nota: De acuerdo con Canavos, “la decisión de rechazar \\(H_0\\) no necesariamente significa que \\(H_0\\) sea falsa”, no obstante, la muestra utilizada para tomar la decisión proporciona un grado de confiabilidad con el que puede procederse como si \\(H_0\\) fuese falsa. 1.3 Región crítica y reglas de decisión Para ciertos valores de la estadística de prueba, la decisión será el rechazar la hipótesis nula, dichos valores se conocen como región crítica. Las reglas de decisión se relacionan con los postulados de \\(H_0\\) y \\(H_1\\). En este caso es importante mencionar que en muchas situaciones el error tipo I se considera como un error mucho más grave que el error tipo II, aceptar la premisa del error tipo I es mucho más serio que el error tipo II. Un principio sencillo y razonable al obtener reglas de decisión para la prueba de hipótesis estadística es seleccionar aquel procedimiento de prueba que tenga el tamaño más pequeño para el error tipo II entre todos los procedimientos que tengan el mismo tamaño para el error tipo I. El valor de \\(\\alpha\\) no puede hacerse muy pequeño sin que se incremente el valor de \\(\\beta\\). En todo caso, el valor de \\(\\beta\\) es igual a la probabilidad de equivocarse al rechazar \\(H_0\\) cuando \\(H_1\\) es cierta. La gráfica ilustra como el tamaño de error tipo I disminuye, pero crece el tamaño del error tipo II. La probabilidad de \\(\\alpha\\) del error tipo I también se conoce como el nivel de significancia estadística. "],["método-del-intervalo-de-confianza.html", "2 Método del intervalo de confianza", " 2 Método del intervalo de confianza Pensemos en \\(X_i\\sim N(\\mu, \\sigma^2)\\) si es así, el estadístico de prueba \\(\\bar{X}\\) está distribuido como \\(\\bar{X}\\sim N(\\mu, \\sigma^2/n)\\). Como conocemos la distribución de probabilidades de \\(\\bar{X}\\), ¿por qué no establecer, por ejemplo, un intervalo de confianza de 100(1-\\(\\alpha\\)) para $$ basada en \\(\\bar{X}\\) y ver si este intervalo incluye \\(\\mu=\\mu^*\\)? Si es así, no rechazamos la hipótesis nula; si no lo es, la rechazamos. En ese caso, si establecemos que \\(\\alpha\\)= 0.05, tendremos un intervalo de confianza a 95%, y si este intervalo de confianza incluye \\(\\mu^*\\), no rechazamos la hipótesis nula, pues es probable que 95 de 100 intervalos así construidos incluyan a \\(\\mu^*\\). El procedimiento es el siguiente: como \\(\\bar{X}\\sim N(\\mu, \\sigma^2/n)\\) se deduce que: $ Z_i=N(0,1)$ Como se trata de una variable normal estandar, sabemos por la tabla de distribución normal $Pr(-1.96 Z_i ) = 0.95 $ Esté corresponde a un intervalo de confianza del 95% para $$. Una vez construido este intervalo, la prueba de la hipótesis nula es simple. Todo lo que debemos hacer es ver si \\(\\mu=\\mu^*\\) se encuentra en este intervalo. Si se encuentra, podemos aceptar la hipótesis nula; si no se encuentra, la podemos rechazar. "],["método-de-la-prueba-de-significancia.html", "3 Método de la prueba de significancia", " 3 Método de la prueba de significancia Dado el valor de $Z_i $ en cualquier aplicación dada, $ {X}$ y $ n$ se conoce (o pueden ser estimados), pero los verdaderos $$ y \\(\\sigma\\) no se conocce. Sin embargo, si $$ es especificado y se supone (bajo \\(H_0\\)) que \\(\\mu=\\mu^*\\), un valor numérico específico, entonces \\(Z_i\\) puede ser directamente calculado y se puede consultar la tabla de distribución normal para encontrar la probabilidad de obtener el valor Z calculado. Si esta probabilidad es baja, por ejemplo, menor que el 5% o que el 1%, se puede rechazar la hipótesis nula - si la hipótesis fuera cierta, la posibilidad de obtener el valor Z particular debe ser muy alta -. Ésta es la idea general en la cual se basa el método de pruebas de significancia para probar hipótesis. La idea clave es el estadístico de prueba (en este caso Z) y su distribución de probabilidad bajo el valor supuesto \\(\\mu=\\mu^*\\). Consideremos un ejemplo donde \\(\\mu=\\mu^*=69\\), por lo tanto, \\(Z = -8\\). Si es así, la probabilidad de obtener el valor de Z es muy inferir al 2.5%, muy por debajo de nuestra probabilidad preespecificada de cometer un error tipo I. Por tal motivo, como se evidencia en la gráfica, el valor calculado de Z = -8 es estadísticamente significativo; es decir, se rechaza la hipótesis nula de que la verdadera \\(\\mu^*=69\\). "],["pasos-prueba-de-hipótesis-estadísticas.html", "4 Pasos prueba de hipótesis estadísticas", " 4 Pasos prueba de hipótesis estadísticas Postular la hipótesis nula $ H_0$ y la hipótesis alterna $ H_1$. Seleccionar el estadístico de prueba. Determinar la distribución de probabilidad del estadístico de prueba. Seleccionar el nivel de significancia (es decir, la probabilidad de cometer un error tipo I) Utilizando la distribucuón de probabilidad del estadístico de prueba, constuir un intervalo de confianza. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
